---
title:          "Describe Anything in Medical Images"
date:           2025-05-05 00:01:00 +0800
selected:       true
pub:            "<strong>ICML 2025 Workshop on Multi-modal Foundation Models and Large Language Models for Life Sciences</strong>"
pub_date:       "2025"
# abstract: >-
#  Localized image captioning has made significant progress with models like the Describe Anything Model (DAM), which can generate detailed region-specific descriptions without explicit region-text supervision. However, such capabilities have yet to be widely applied to specialized domains like medical imaging, where diagnostic interpretation relies on subtle regional findings rather than global understanding. To mitigate this gap, we propose MedDAM, the first comprehensive framework leveraging large vision-language models for region-specific captioning in medical images.
cover:          /assets/images/covers/medam.png
authors:
- Xi Xiao
- Yunbei Zhang
- Thanh-Huy Nguyen
- Ba-Thinh Lam
- Janet Wang
- Lin Zhao
- Jihun Hamm
- Tianyang Wang
- Xingjian Li
- Xiao Wang
- Hao Xu
- Tianming Liu
- Min Xu
links:
  PDF: https://arxiv.org/pdf/2505.05804
---
